{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vempaliakhil96/kaggle-entailment-competition/blob/main/03-exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ff57ddee",
      "metadata": {
        "id": "ff57ddee"
      },
      "outputs": [],
      "source": [
        "! pip install fastkaggle fastai pandas fastcore tqdm datasets transformers[torch] accelerate --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c14dcd2",
      "metadata": {
        "id": "0c14dcd2"
      },
      "outputs": [],
      "source": [
        "from fastkaggle import *\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "from fastai.text.all import *\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import datasets\n",
        "from transformers import TrainingArguments,Trainer\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "tqdm.pandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c0a2a16",
      "metadata": {
        "id": "7c0a2a16"
      },
      "outputs": [],
      "source": [
        "if not iskaggle: api = import_kaggle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d3b00cd",
      "metadata": {
        "id": "7d3b00cd"
      },
      "outputs": [],
      "source": [
        "comp_name = \"contradictory-my-dear-watson\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0202780f",
      "metadata": {
        "id": "0202780f"
      },
      "outputs": [],
      "source": [
        "dpath = setup_comp(comp_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae9b1ac9",
      "metadata": {
        "id": "ae9b1ac9"
      },
      "outputs": [],
      "source": [
        "dpath.ls()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3987b855",
      "metadata": {
        "id": "3987b855"
      },
      "outputs": [],
      "source": [
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else device\n",
        "mname = 'cross-encoder/nli-distilroberta-base'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(mname, num_labels=3).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(mname)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4ddfa51",
      "metadata": {
        "id": "a4ddfa51"
      },
      "outputs": [],
      "source": [
        "def baseline_prediction(premise, hypothesis):\n",
        "    toks = tokenizer([premise], [hypothesis], return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "    scores = model(**toks).logits\n",
        "    label_mapping = ['contradiction', 'entailment', 'neutral']\n",
        "    label = [label_mapping[score_max] for score_max in scores.argmax(dim=1)]\n",
        "    return label[0]\n",
        "\n",
        "def bulk_baseline_predict(premises, hypotheses):\n",
        "    labels = []\n",
        "    bs = 8\n",
        "    for i in tqdm(range(0, len(premises), bs)):\n",
        "        toks = tokenizer(premises[i:i+bs], hypotheses[i:i+bs], return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "        scores = model(**toks).logits\n",
        "        label_mapping = ['contradiction', 'entailment', 'neutral']\n",
        "        _labels = [label_mapping[score_max] for score_max in scores.argmax(dim=1)]\n",
        "        labels.extend(_labels)\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fbc7ee3",
      "metadata": {
        "id": "3fbc7ee3"
      },
      "outputs": [],
      "source": [
        "comp_id2label = {\n",
        "    0: \"entailment\",\n",
        "    1: \"neutral\",\n",
        "    2: \"contradiction\"\n",
        "}\n",
        "label2comp_id = {v:k for k,v in comp_id2label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d8314ec",
      "metadata": {
        "id": "6d8314ec"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(dpath/\"train.csv\")\n",
        "test_df = pd.read_csv(dpath/\"test.csv\")\n",
        "\n",
        "def _process_text(text): return fix_html(rm_useless_spaces(spec_add_spaces(text)))\n",
        "\n",
        "def tokfn(x): return tokenizer(x[\"input\"])\n",
        "\n",
        "train_df.premise = train_df.premise.apply(_process_text)\n",
        "train_df.hypothesis = train_df.hypothesis.apply(_process_text)\n",
        "train_df.label = train_df.label.map(comp_id2label).map(model.config.label2id)\n",
        "test_df.premise = test_df.premise.apply(_process_text)\n",
        "test_df.hypothesis = test_df.hypothesis.apply(_process_text)\n",
        "train_df[\"input\"] = \"premise: \" + train_df.premise + \"\\nhypothesis: \" + train_df.hypothesis\n",
        "test_df[\"input\"] = \"premise: \" + test_df.premise + \"\\nhypothesis: \" + test_df.hypothesis\n",
        "\n",
        "train_ds = datasets.Dataset.from_pandas(train_df[[\"input\", \"label\"]])\n",
        "test_ds = datasets.Dataset.from_pandas(test_df[[\"id\", \"input\"]])\n",
        "train_ds = train_ds.train_test_split(test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3585a4e-a47a-415f-945b-a88ddff82e5c",
      "metadata": {
        "id": "d3585a4e-a47a-415f-945b-a88ddff82e5c"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(tokfn, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaa80f1e-d661-4c19-91e9-d8d4805533c3",
      "metadata": {
        "id": "aaa80f1e-d661-4c19-91e9-d8d4805533c3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16ffaae2-be91-492d-9711-cc9f2cf14616",
      "metadata": {
        "id": "16ffaae2-be91-492d-9711-cc9f2cf14616"
      },
      "outputs": [],
      "source": [
        "bs = 8\n",
        "epochs = 4\n",
        "lr = 8e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c40ecffd-aae1-4d0f-99b0-716aceef48f2",
      "metadata": {
        "id": "c40ecffd-aae1-4d0f-99b0-716aceef48f2"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments('outputs',\n",
        "                         learning_rate=lr,\n",
        "                         warmup_ratio=0.1,\n",
        "                         lr_scheduler_type='cosine',\n",
        "                         fp16=True if torch.cuda.is_available() else False,\n",
        "                         evaluation_strategy=\"epoch\",\n",
        "                         per_device_train_batch_size=bs,\n",
        "                         per_device_eval_batch_size=bs*2,\n",
        "                         num_train_epochs=epochs,\n",
        "                         weight_decay=0.01,\n",
        "                         report_to='none')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1792e0b7-fb99-45b5-a72b-d4860f014530",
      "metadata": {
        "id": "1792e0b7-fb99-45b5-a72b-d4860f014530"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model, args,\n",
        "                  train_dataset=train_ds['train'],\n",
        "                  eval_dataset=train_ds['test'],\n",
        "                  tokenizer=tokenizer,\n",
        "                  compute_metrics=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4a1182e-4557-4349-90c4-760fd43eee6c",
      "metadata": {
        "id": "f4a1182e-4557-4349-90c4-760fd43eee6c"
      },
      "outputs": [],
      "source": [
        "trainer.train();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f56ad5b2-b4f3-4b8a-81ff-875f02bb53e9",
      "metadata": {
        "id": "f56ad5b2-b4f3-4b8a-81ff-875f02bb53e9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7391e76",
      "metadata": {
        "id": "b7391e76"
      },
      "outputs": [],
      "source": [
        "if not iskaggle:\n",
        "    push_notebook('vempaliakhil96', '03-exp',\n",
        "                  title='03-exp',\n",
        "                  file='03-exp.ipynb',\n",
        "                  competition=comp_name,\n",
        "                  private=False,\n",
        "                  gpu=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9a57d0e-8d54-45a2-8e40-3be37fda8a37",
      "metadata": {
        "id": "f9a57d0e-8d54-45a2-8e40-3be37fda8a37"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}